import sys
import os
import glob
import torch
from pathlib import Path

# ---------------------------------------------------------
# ëª¨ë“ˆ ì„í¬íŠ¸
# (ì£¼ì˜: ì•„ë˜ ëª¨ë“ˆë“¤ì€ ê²½ë¡œë¥¼ ì¸ìë¡œ ë°›ë„ë¡ ìˆ˜ì •ëœ ë²„ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤)
# ---------------------------------------------------------
from tracker import run_track_and_save
from roi_pick import get_roi_points
from make_videos import images_to_video
import mediapipe_test as medpip
import media_csv_v2 as medcsv
import infinf as inf

# =========================================================
# [ì„¤ì •] ê²½ë¡œ ë° íŒŒë¼ë¯¸í„°
# =========================================================
# 1. ì…ë ¥ ì˜ìƒ
VIDEO_FILE = "inputs/normal_test2.mp4"

# 2. ëª¨ë¸ ê²½ë¡œ
YOLO_MODEL = "yolo11n.pt"
TRACKER_YAML = "botsort.yaml"
LSTM_CKPT = Path("inference/epoch_015.pt") # LSTM ëª¨ë¸ ìœ„ì¹˜

# 3. ì¶œë ¥ ê²½ë¡œ ì„¤ì •
BASE_OUT_DIR = "outputs"
BOTSORT_DIR = os.path.join(BASE_OUT_DIR, "botsort")
PERSON_CROP_DIR = os.path.join(BOTSORT_DIR, "person")
VIDEO_OUT_DIR = os.path.join(BASE_OUT_DIR, "person_videos")
INFERENCE_OUT_DIR = os.path.join(BASE_OUT_DIR, "inference")

def main():
    # # -----------------------------------------------------
    # # Step 1: ROI ì„¤ì • ë° ê°ì²´ ì¶”ì  (YOLO + BotSORT)
    # # -----------------------------------------------------
    # print("\n" + "="*60)
    # print(">>> [Step 1] ROI ì„¤ì • ë° ê°ì²´ ì¶”ì  ì‹œì‘")
    # print("="*60)

    # # ROI ì„ íƒ
    # print(">>> ROI ì„ íƒ ì°½ì„ ì—½ë‹ˆë‹¤...")
    # selected_points = get_roi_points(VIDEO_FILE)

    # if len(selected_points) < 3:
    #     print("\n[ê²½ê³ ] ì ì´ 3ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ROI ì„¤ì • ì—†ì´ ì§„í–‰í•˜ë ¤ë©´ ì—”í„°.")
    
    # print(">>> YOLO AI ëª¨ë¸ ë¡œë”© ë° ë¶„ì„ ì‹œì‘...")
    
    # # íŠ¸ë˜í‚¹ ì‹¤í–‰
    # run_track_and_save(
    #     video_path=VIDEO_FILE,      
    #     out_dir=BOTSORT_DIR,  
    #     roi_points=selected_points, 
        
    #     tracker_yaml=TRACKER_YAML,
    #     model_path=YOLO_MODEL,
    #     conf=0.10,                  
    #     imgsz=1280,                 
    #     save_vis=True,              
    #     save_bbox_csv=True,         
    #     bbox_only_person=True,      
    #     save_crops=True,            

    #     enable_id_fix=True,         
    #     idfix_max_age=45,           
    #     idfix_use_appearance=True,
    #     crop_padding=0.5 
    # )

    # # -----------------------------------------------------
    # # Step 2: í¬ë¡­ ì´ë¯¸ì§€ -> ì˜ìƒ ë³€í™˜
    # # -----------------------------------------------------
    # print("\n" + "="*60)
    # print(">>> [Step 2] ì¶”ì ëœ ê°ì²´(ì‚¬ëŒ)ë¥¼ ì˜ìƒìœ¼ë¡œ ë³€í™˜")
    # print("="*60)
    
    # # images_to_video í•¨ìˆ˜ê°€ outputs/person_videos ì— .mp4 ìƒì„±
    # images_to_video(
    #     input_root=PERSON_CROP_DIR,
    #     output_root=VIDEO_OUT_DIR,
    #     fps=30
    # )

    # -----------------------------------------------------
    # Step 3: ì´ìƒ í–‰ë™ ì¶”ë¡  (MediaPipe -> CSV -> LSTM)
    # -----------------------------------------------------
    print("\n" + "="*60)
    print(">>> [Step 3] ì´ìƒ í–‰ë™(Normal/Abnormal) ì¶”ë¡  ì‹œì‘")
    print("="*60)

    # 3-1. ìƒì„±ëœ ë¹„ë””ì˜¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    video_files = glob.glob(os.path.join(VIDEO_OUT_DIR, "*.mp4"))
    if not video_files:
        print("[ì•Œë¦¼] ìƒì„±ëœ ì‚¬ëŒ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ë¡ ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 3-2. LSTM ëª¨ë¸ ë¡œë“œ (1íšŒ)
    device = torch.device("mps")
    print(f">>> LSTM ëª¨ë¸ ë¡œë”© ì¤‘... (Device: {device})")
    
    try:
        model, model_cfg = inf.load_model(LSTM_CKPT, device)
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 3-3. ê° ë¹„ë””ì˜¤ë³„ ì²˜ë¦¬ ë£¨í”„
    results = []
    os.makedirs(INFERENCE_OUT_DIR, exist_ok=True)

    for v_path in sorted(video_files):
        filename = os.path.basename(v_path)
        file_id = os.path.splitext(filename)[0] # ì˜ˆ: id_0001
        
        print(f"\n--- Processing: {file_id} ---")
        
        # íŒŒì¼ ê²½ë¡œ ì •ì˜
        npz_path = os.path.join(INFERENCE_OUT_DIR, f"{file_id}.npz")
        csv_path = os.path.join(INFERENCE_OUT_DIR, f"{file_id}.csv")

        # (A) MediaPipe ì¶”ì¶œ (Video -> NPZ)
        if not medpip.process_video(v_path, npz_path):
            print(f"   -> [Skip] MediaPipe ì¶”ì¶œ ì‹¤íŒ¨")
            continue

        # (B) CSV ë³€í™˜ ë° ì „ì²˜ë¦¬ (NPZ -> CSV)
        if not medcsv.process_npz_to_csv(npz_path, csv_path):
            print(f"   -> [Skip] CSV ë³€í™˜ ì‹¤íŒ¨ (ë°ì´í„° ë¶€ì¡± ë“±)")
            continue

        # (C) ì¶”ë¡  (CSV -> Result)
        try:
            res = inf.predict_single(model, csv_path, device, model_cfg)
            
            status = "ABNORMAL ğŸš¨" if res['pred_class'] == 1 else "Normal âœ…"
            prob = res['p_abnormal'] if res['pred_class'] == 1 else res['p_normal']
            
            print(f"   -> ê²°ê³¼: {status} ({prob:.2%})")
            
            results.append({
                "id": file_id,
                "status": status,
                "prob": prob
            })
            
        except Exception as e:
            print(f"   -> [ì˜¤ë¥˜] ì¶”ë¡  ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

    # -----------------------------------------------------
    # ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸
    # -----------------------------------------------------
    print("\n" + "="*60)
    print("FINAL SUMMARY REPORT")
    print("="*60)
    if not results:
        print("ê²€ì¶œëœ ìœ íš¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for r in results:
            print(f"ID: {r['id']:<10} | {r['status']} (í™•ë¥ : {r['prob']:.4f})")
    print("="*60)

   # -----------------------------------------------------
    # Step 4: ìµœì¢… ë°ëª¨ ì˜ìƒ ìƒì„± (Overlay)
    # -----------------------------------------------------

    import json
    from overlay_demo import render

    # results ë¦¬ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ ì €ì¥(overlay_demo.pyê°€ ì½ì„ í¬ë§·)
    os.makedirs(INFERENCE_OUT_DIR, exist_ok=True)
    results_json_path=os.path.join(INFERENCE_OUT_DIR, "results.json")
    with open(results_json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # bboxes.csv ê²½ë¡œ(í˜„ì¬ tracker.py ê¸°ì¤€)
    bboxes_csv=os.path.join(BOTSORT_DIR, "bboxes.csv")

    # ìµœì¢… ë°ëª¨ ì˜ìƒ ê²½ë¡œ
    final_demo=os.path.join(BASE_OUT_DIR, "final_demo_deco.mp4")

    render(
        video_path=VIDEO_FILE,
        bboxes_csv=bboxes_csv,
        results_json=results_json_path,
        out_path=final_demo,
        only_person=True,
        smooth=True,
    )

    print(f"[DONE] Final demo saved: {final_demo}")    

if __name__ == "__main__":
    main()